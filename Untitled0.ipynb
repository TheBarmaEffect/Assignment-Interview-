{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOki12rIPU3vwuAV1vppNdo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheBarmaEffect/Assignment-Interview-/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "ouerGK1mU2k4",
        "outputId": "12f122ab-1c97-49a1-865b-b225cf8c5641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Dictionary:\n",
            "              COLUMN NAME                 COLUMN DESCRIPTION\n",
            "0               DEALER ID    Unique identifier of the dealer\n",
            "1  APPLICATION LOGIN DATE  Date of submission of application\n",
            "2         HDB BRANCH NAME                Bank branch details\n",
            "3        HDB BRANCH STATE                                NaN\n",
            "4              FIRST NAME                  Submitted Details\n",
            "Categorical Features: ['ASSET CTG']\n",
            "Numerical Features: ['Cibil Score', 'MOBILE VERIFICATION', 'ASSET MODEL NO', 'Primary Asset Model No', 'phone_digitalage', 'phone_phoneFootprintStrengthOverall']\n",
            "Special Handling Features: ['DEALER ID', 'APPLICATION LOGIN DATE', 'HDB BRANCH NAME', 'HDB BRANCH STATE', 'FIRST NAME', 'MIDDLE NAME', 'LAST NAME', 'mobile', 'AADHAR VERIFIED', 'DEALER NAME', 'TOTAL ASSET COST', 'LOS ID', 'APPLIED AMOUNT', 'PRIMARY ASSET MAKE', 'Personal Email Address', 'MARITAL STATUS', 'GENDER', 'DOB', 'AGE', 'ADDRESS TYPE', 'EMPLOY CONSTITUTION', 'EMPLOYER NAME', 'EMPLOYER TYPE', 'Pan Name', 'name', 'vpa', 'upi_name', 'Phone Social Premium.a23games', 'Phone Social Premium.amazon', 'Phone Social Premium.byjus', 'Phone Social Premium.flipkart', 'Phone Social Premium.housing', 'Phone Social Premium.indiamart', 'Phone Social Premium.instagram', 'Phone Social Premium.isWABusiness', 'Phone Social Premium.jeevansaathi', 'Phone Social Premium.jiomart', 'Phone Social Premium.microsoft', 'Phone Social Premium.my11', 'Phone Social Premium.paytm', 'Phone Social Premium.rummycircle', 'Phone Social Premium.shaadi', 'Phone Social Premium.skype', 'Phone Social Premium.toi', 'Phone Social Premium.whatsapp', 'Phone Social Premium.yatra', 'Phone Social Premium.zoho', 'phone_nameMatchScore', 'Application Status']\n",
            "Accuracy: 0.9992\n",
            "Precision: 0.9991\n",
            "Recall: 0.9997\n",
            "F1-Score: 0.9994\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    APPROVED       1.00      1.00      1.00      6677\n",
            "    DECLINED       1.00      1.00      1.00      3323\n",
            "\n",
            "    accuracy                           1.00     10000\n",
            "   macro avg       1.00      1.00      1.00     10000\n",
            "weighted avg       1.00      1.00      1.00     10000\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[6675    2]\n",
            " [   6 3317]]\n",
            "Predictions have been saved to 'predictions.csv'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0572da33-7c32-48ca-aa8e-9ac9baf37f12\", \"predictions.csv\", 57011)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load datasets (Make sure to upload the files to Colab first)\n",
        "train_df = pd.read_csv('/content/Assignment_Train.csv')\n",
        "test_df = pd.read_csv('/content/Assignment_Test.csv')\n",
        "feature_dict = pd.read_excel('/content/Assignment_FeatureDictionary.xlsx')\n",
        "\n",
        "# Display the Feature Dictionary to understand the features\n",
        "print(\"Feature Dictionary:\")\n",
        "print(feature_dict.head())\n",
        "\n",
        "# Create a dictionary to map feature names to their descriptions\n",
        "feature_mapping = dict(zip(feature_dict['COLUMN NAME'], feature_dict['COLUMN DESCRIPTION']))\n",
        "\n",
        "# Use the feature dictionary to guide preprocessing and feature engineering\n",
        "categorical_features = []\n",
        "numerical_features = []\n",
        "special_handling_features = []\n",
        "\n",
        "# Categorize features based on their descriptions\n",
        "for feature, description in feature_mapping.items():\n",
        "    description = str(description)  # Ensure the description is a string\n",
        "    if 'categorical' in description.lower() or 'category' in description.lower():\n",
        "        categorical_features.append(feature)\n",
        "    elif 'numeric' in description.lower() or 'number' in description.lower() or 'score' in description.lower():\n",
        "        numerical_features.append(feature)\n",
        "    else:\n",
        "        special_handling_features.append(feature)\n",
        "\n",
        "print(\"Categorical Features:\", categorical_features)\n",
        "print(\"Numerical Features:\", numerical_features)\n",
        "print(\"Special Handling Features:\", special_handling_features)\n",
        "\n",
        "# Drop columns with 100% missing data in the test set\n",
        "columns_to_drop = ['Phone Social Premium.a23games', 'Phone Social Premium.my11',\n",
        "                   'Phone Social Premium.rummycircle', 'Phone Social Premium.yatra']\n",
        "train_df_cleaned = train_df.drop(columns=columns_to_drop)\n",
        "test_df_cleaned = test_df.drop(columns=columns_to_drop)\n",
        "\n",
        "# Ensure all numerical features are numeric, convert non-numeric to NaN\n",
        "for column in numerical_features:\n",
        "    train_df_cleaned[column] = pd.to_numeric(train_df_cleaned[column], errors='coerce')\n",
        "    test_df_cleaned[column] = pd.to_numeric(test_df_cleaned[column], errors='coerce')\n",
        "\n",
        "# Identify and remove columns with only missing values (NaNs)\n",
        "missing_train = train_df_cleaned[numerical_features].isna().all()\n",
        "missing_test = test_df_cleaned[numerical_features].isna().all()\n",
        "cols_to_remove = missing_train[missing_train].index.tolist() + missing_test[missing_test].index.tolist()\n",
        "numerical_features = [col for col in numerical_features if col not in cols_to_remove]\n",
        "\n",
        "# Re-check and remove any columns with remaining NaN values after imputation\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "train_df_cleaned[numerical_features] = imputer_num.fit_transform(train_df_cleaned[numerical_features])\n",
        "test_df_cleaned[numerical_features] = imputer_num.transform(test_df_cleaned[numerical_features])\n",
        "\n",
        "train_df_cleaned[categorical_features] = imputer_cat.fit_transform(train_df_cleaned[categorical_features])\n",
        "test_df_cleaned[categorical_features] = imputer_cat.transform(test_df_cleaned[categorical_features])\n",
        "\n",
        "# Double-check and drop any remaining columns with NaN values\n",
        "train_df_cleaned.dropna(axis=1, inplace=True)\n",
        "test_df_cleaned.dropna(axis=1, inplace=True)\n",
        "\n",
        "# Feature Engineering: Scale numerical features (optional but often beneficial)\n",
        "scaler = StandardScaler()\n",
        "train_df_cleaned[numerical_features] = scaler.fit_transform(train_df_cleaned[numerical_features])\n",
        "test_df_cleaned[numerical_features] = scaler.transform(test_df_cleaned[numerical_features])\n",
        "\n",
        "# Prepare target and features\n",
        "X = train_df_cleaned.drop(columns=['Application Status'])\n",
        "y = train_df_cleaned['Application Status']\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "for column in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    X[column] = le.fit_transform(X[column])\n",
        "    test_df_cleaned[column] = le.transform(test_df_cleaned[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "# Ensure columns match\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "test_df_encoded = pd.get_dummies(test_df_cleaned, drop_first=True)\n",
        "\n",
        "# Ensure columns match\n",
        "test_df_encoded = test_df_encoded.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "# Double-check for any remaining NaN values in X\n",
        "if X.isnull().values.any():\n",
        "    print(\"Warning: There are still NaN values in X after preprocessing.\")\n",
        "else:\n",
        "    # Train a RandomForestClassifier\n",
        "    rf_model = RandomForestClassifier(random_state=42)\n",
        "    rf_model.fit(X, y)\n",
        "\n",
        "    # Evaluate the model on training data\n",
        "    train_predictions = rf_model.predict(X)\n",
        "\n",
        "    accuracy = accuracy_score(y, train_predictions)\n",
        "    precision = precision_score(y, train_predictions, pos_label='APPROVED')\n",
        "    recall = recall_score(y, train_predictions, pos_label='APPROVED')\n",
        "    f1 = f1_score(y, train_predictions, pos_label='APPROVED')\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y, train_predictions))\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y, train_predictions))\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    test_predictions = rf_model.predict(test_df_encoded)\n",
        "\n",
        "    # Prepare output file\n",
        "    output_df = pd.DataFrame({\n",
        "        'UID': test_df['UID'],\n",
        "        'Prediction': test_predictions\n",
        "    })\n",
        "\n",
        "    # Save the predictions to a CSV file\n",
        "    output_df.to_csv('/content/predictions.csv', index=False)\n",
        "    print(\"Predictions have been saved to 'predictions.csv'\")\n",
        "\n",
        "    # Download the file if running on Colab\n",
        "    from google.colab import files\n",
        "    files.download('/content/predictions.csv')\n"
      ]
    }
  ]
}